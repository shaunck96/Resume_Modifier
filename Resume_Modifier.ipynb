{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONTqYlm1LKiIs9IJZXqZwK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaunck96/Resume_Modifier/blob/main/Resume_Modifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.35.2\n",
        "!pip install requests==2.31.0\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install openai==0.28\n",
        "!pip install eyed3==0.9.7\n",
        "!pip install tiktoken==0.5.1\n",
        "!pip install langchain==0.0.340\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhIrlWnXlwHm",
        "outputId": "5f11feec-2d27-4b43-9629-e855091c0269"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (2023.11.17)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2023.11.17)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n",
            "Collecting eyed3==0.9.7\n",
            "  Downloading eyed3-0.9.7-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coverage[toml]<6.0.0,>=5.3.1 (from eyed3==0.9.7)\n",
            "  Downloading coverage-5.5-cp310-cp310-manylinux1_x86_64.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation<3.0.0,>=2.1.0 (from eyed3==0.9.7)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.0.7 (from eyed3==0.9.7)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from coverage[toml]<6.0.0,>=5.3.1->eyed3==0.9.7) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation<3.0.0,>=2.1.0->eyed3==0.9.7) (23.2)\n",
            "Installing collected packages: filetype, deprecation, coverage, eyed3\n",
            "Successfully installed coverage-5.5 deprecation-2.1.0 eyed3-0.9.7 filetype-1.2.0\n",
            "Collecting tiktoken==0.5.1\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n",
            "Collecting langchain==0.0.340\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.9.1)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.340)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.340)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.340)\n",
            "  Downloading langsmith-0.0.79-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.340)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.340) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.340) (3.0.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.340 langsmith-0.0.79 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.0.11-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.3)\n",
            "Collecting langchain-core<0.2,>=0.1.8 (from langchain_community)\n",
            "  Downloading langchain_core-0.1.9-py3-none-any.whl (216 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.0.79)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.8->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.8->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.8->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.8->langchain_community) (1.10.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2023.11.17)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.8->langchain_community) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.8->langchain_community) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.8->langchain_community) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Installing collected packages: langchain-core, langchain_community\n",
            "Successfully installed langchain-core-0.1.9 langchain_community-0.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import regex as re\n",
        "import json\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from googleapiclient.discovery import build\n",
        "import regex as re\n",
        "from transformers import pipeline\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "import re\n",
        "from urllib import parse\n",
        "\n",
        "import torch\n",
        "import ast\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from itertools import islice\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from itertools import islice\n",
        "\n",
        "import base64\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import googleapiclient.discovery\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
        "from langchain.llms import OpenAI\n",
        "import requests\n",
        "import requests\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvlXK1cklwFP",
        "outputId": "263ba93b-bdc3-40ec-b20a-e5b1eb3ddaec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQzQmla5kryG",
        "outputId": "9bee4376-db74-4d57-bc56-10af65b65e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "import time\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "-WS-UpAEk5Vy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "pdf_path = (\n",
        "    Path.home()\n",
        "    / \"creating-and-modifying-pdfs\"\n",
        "    / \"practice_files\"\n",
        "    / \"/content/Shaun Resume Final.pdf\"\n",
        ")"
      ],
      "metadata": {
        "id": "aoPQUQDYk5qs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_reader = PdfReader(pdf_path)\n",
        "pdf_reader.metadata\n",
        "pages = \"\"\n",
        "for page in pdf_reader.pages:\n",
        "    print(page.extract_text())\n",
        "    pages+=page.extract_text()\n",
        "    pages+=\"\\n\\n\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPPSsUOalH9D",
        "outputId": "b75ea3ca-dfed-4fb0-fd90-e451f7600222"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAUNCHACKOSHIBU\n",
            "JerseyCity,NJ07307|shaunchackoofficial@gmail.com|+1(610)570-2109LinkedIn|Kaggle|Github\n",
            "SUMMARY______________________________________________________________________________________________________________________________________________________________________________DedicatedandaccomplishedSeniorDataScientistwith4yearsofprogressivelyadvancedexperiencespecializinginNaturalLanguageProcessing(NLP)andGenerativeAI.ProventrackrecordofarchitectinganddeployingAIsolutionstoaddressdiversebusinesschallengesanddriverevenuegrowth.Adeptatleadingend-to-endprojectlifecycles,fromresearchandplanningtodeployment,whileadheringtostandardizedMLOpsprinciples.Highlyskilledineffectivelycommunicatingintricateconceptstodiversestakeholders,fosteringcollaborationanddrivingsuccessfulprojectoutcomes.\n",
            "PROFESSIONALEXPERIENCE______________________________________________________________________________________________________________________________________________________________________________S e n i o rD a t aS c i e n t i s t ,PPLCORPORATION|A l l e n t o w n ,P AD e c2 0 2 1–P r e s e n tLeadingateamof3datascientists.Heavilyinvolvedindeveloping,deployingandmanagingendtoendmachinelearningprojectlifecyclesintheCustomerServiceandAssetManagementindustryAnnualcostsavings:$2M\n",
            "NLP(GenAI,TopicModelling,SentimentAnalysis)-DevelopedastateoftheartGenAIpoweredchatbotframework(Currentstate-AzureOpenAI,FutureState-AzureLlama2)thatingestsrecordsofcalltranscriptionsatthecustomerservicecentertogeneratecrispsummariesandidentifytrendingissuesfacedbycustomers,supportedautomatedhandlingofcustomerrequestsandimprovetheexistingcustomerserviceIVRsystem-Developedacallclassificationframeworkusingtopicmodelingtoactivelyclassifyincomingcustomercallsintohighlevelcategoriestosupportagentleveltraining,identifyleadingissuesfacedbycustomers,reducequeuetimesby45%-DevelopedaLLMpoweredsentimentanalysisframeworktoidentifyareasofleadingnegativesentimentincustomersurveysandrelevantaspectsofnegativesentimentusingservicefeedbackonwebsiteandcustomerservicecentercalltranscriptions-Ledthedevelopment,integrationanddeploymentofAzureOpenAIresourcewithexistingPPLecosystemtosupportdeploymentofLLMpoweredapplicationstoproductionRegulatoryComplianceSummaries-Collaboratedcloselywithlegalandregulatoryteamstoidentifycrucialcomplianceparametersandrequirements.-HarnessedthepowerofLLMstoprocessintricatelegallanguageandextractkeyregulatoryclauses,obligations,andimplications,utilizingAzureOpenAIservicesforrapidmodeldeploymentandseamlessintegrationofthesummarizationsystemintoexistingworkflows.-Achievedsubstantialtimesavingsinthereviewofcomplexregulations,generatingconciseandcontextuallyaccuratecompliancesummaries.-Empoweredregulatoryprofessionalstoefficientlyassesscompliancestatusandtaketimelycorrectiveactions,minimizingrisk.SemanticSegmentation(LiDARPointCloudClassification)-DevelopedanddeployedasemanticsegmentationframeworktoclassifypointcloudLIDARdatausingdeeplearningCNNframework(KPConv)toclassifypolesandidentifyareasofvegetationencroachmentsandreducenetworkwideunplannedoutagesby37%TimeSeriesForecasting-Developedanddeployedanendtoendtimeseriesforecastingframeworktopredictthetotaldemandforelectricitybythehourinordertosupportoperationalplanningandreducestaffingexpensesby$1.2MannuallyA/BTesting,CustomerSegmentation-DevelopedandimplementedA/Btestingframeworktoexperimentvariouscampaigninginitiativesandidentifyhighpropensitytochurncustomersandreduceannualcampaigningexpensesby$150Kannually-Generatedcustomersegmentsbasedonvariousexperian,demographicandusagespecificcharacteristicstosupporttargetedcampaigninginitiativesProjectManagement-Developedandmaintainedcookiecuttertemplatesanddevopsboardstoactivelytrackprojectandpushchangestoprojectrelatedcode-EstablishedbestpracticesoverusageofMSAzureandAzureDevopsfordatascienceprojectmanagementanddeploymentofMLmodelscompanywideIntegrationofNewTechnologies-SuccessfullyledtheintegrationofanewAItechnologies,AzureOpenAI,todeliverstateoftheartNLPsolutionstovariousstakeholderswithintheorgToolsused:DeepLearning·AzureOpenAI·GitHub·MicrosoftAzure·AzureDatabricks·MicrosoftVisualStudioCode·MicrosoftPowerBI·LargeLanguageModels(LLM)·NaturalLanguageProcessing(NLP)·SentimentAnalysis·TopicModeling·AutomaticTextSummarization·LLMOps·TimeSeriesForecasting·LangChain·PromptEngineering·ConvolutionalNeuralNetworks(CNN)·LiDAR·GenerativeAI·Leadership·C++·Python(ProgrammingLanguage)·PySpark·Clustering\n",
            "D a t aS c i e n t i s t,CHEWY|W i l k e sB a r r e ,P AJ u l2 0 2 0–D e c2 0 2 1Ledateamof2dataanalysts.Developedanddeployeddatadriven,machinelearningbasedsolutionstosolvevariousbusinessusecasesinthesupplychain,fulfillmentandcustomerserviceindustryAnnualCostsavings:$1.5M\n",
            "PredictiveFrameworkforOnTimeShipping-ImplementedalightgradientboostingframeworktopredicttheprobabilityoforderdeliverydelaysandsuccessfullyreducedOnTimeShippingMissesby22%annually,enhancingcustomersatisfactionandoperationalefficiency.TopicModelPipelinesforCustomerReviewAnalysis-Utilizednaturallanguageprocessingandleddeploymentofadvancedtopicmodelpipelinesforpetproductandservicereviewsanalysistooptimizeproductofferings,improvecustomersatisfactionandimprovedrepeatpurchasesby25%andcustomerretentionby32%TimeSeriesForecastingforOrderVolumePrediction-DeployedarobusttimeseriesforecastingframeworktopredictordervolumesacrosseachfulfillmentcenterintheChewyFCNetworktopredictordervolumesbyshiftandhour,tosupportsales,operations,laborplanningandsupplychainteams-Improvedannualstaffingandoperationalexpensesby$1MannuallyMachineLearningModelIntegrationwithCloudPlatform-Ledtheintegrationofmachinelearningmodelswithacloud-basedplatform(AWS)forscalabilityandefficientmaintenance.-Ensuredseamlessdeploymentofmodelupdates,parametertuning,accuracyevaluation,andtrainingdatamanagement.Company-WidePresentationandIntegrationofNewTechnologies-PresentedthesupplychainandfulfillmentoptimizationframeworktotheentirecompanyduringtheAnnualChewyDataSummit-SuccessfullyledtheintegrationoftwonewAItechnologies,FlexsimandOptiSlot,toguideAIpoweredfulfillmentnetworkdesignandSKUslottingoptimizationToolsused:Skills:Knime·QlikSense·MLOps·NaturalLanguageProcessing(NLP)·TimeSeriesForecasting·Python(ProgrammingLanguage)·SQL\n",
            "I n d u s t r i a lE n g i n e e r i n gI n t e r n,ENERSYS|R e a d i n g ,P AM a y2 0 1 9–A u g2 0 1 9InternshipduringmymastersatLehigh,whereIcontributedtobuildingdatawarehousingandpredictivesolutionsinthebatteryproductionindustry\n",
            "DataWarehouseETLInfrastructureDevelopment-Engineeredarobustinfrastructuretofacilitateoptimalextraction,transformation,andloading(ETL)ofdatafromacomplexdatawarehouse.-EmployedSQLtostreamlinedataextractionandtransformationprocesses,ensuringhigh-qualityandstructureddatainputs.DemandForecastingModelforInventoryImprovement-Developedandimplementedasophisticateddemandforecastingregressionmodeltoenhanceinventoryallocationstrategies.-Achievedanimpressive15%improvementininventoryallocationaccuracy,optimizingresourceutilizationandreducingwaste.Toolsused:Python(ProgrammingLanguage)·SQL·DatabaseSystems\n",
            "D a t aA n a l y s t,PETROGASAGENCIES|A b uD h a b i ,U A EJ a n2 0 1 7–J u l2 0 1 8Deployeddatadrivensolutionstoimprovewebsiteperformancemetricsandrevampproductrecommendationstrategiesintheoilandgasindustry\n",
            "WebMetricsandPerformanceInsights-Definedandtrackedkeywebmetrics,includingpageviews,bouncerates,andconversionrates.-Utilizeddailyclickstreamdatatoprovideweeklyinsightstothedevelopmentandplanningteam,resultingina12%increaseinoverallconversionrates.-Enableddata-drivendecision-makingforcontinuousimprovement,leadingtoa20%reductioninwebsitebouncerates.ProductRecommendationSystem-Successfullyestablishedasophisticatedproductrecommendationsystemthattransformedthee-commerceplatformintoapersonalizedshoppingexperience.-Significantlyincreasedsalesrevenuethroughtargetedcross-sellingandupselling,reflectinga25%boostinoverallsales.-Enhanceduserengagementandsatisfactionbypresentinguserswithproductsalignedwiththeirpreferences,leadingtoa15%increaseincustomerretention.-Contributedtothewebsite'sreputationasacutting-edgeplatformthatutilizesAIandmachinelearningtoenhancecustomerexperiences.Toolsused:Python(ProgrammingLanguage)·SQL\n",
            "TECHNICALSKILLS______________________________________________________________________________________________________________________________________________________________________________-ProgrammingLanguages:Python,R,C++,SQL-MachineLearningFrameworks:PyTorch,Langchain,HuggingFace,Scikit-Learn-BigDataTechnologies:Pyspark,Databricks,AzureDatabricks\n",
            "-CloudPlatforms:MicrosoftAzure,AWS-AITechnologies:AzureOpenAI,HuggingFace,Kubernetes-VersionControl:Git,Gitbash-VisualizationTools:Tableau,MicrosoftPowerBI-MachineLearningOperations(MLOps):AzureMLOps(LLMOps),AzureDevOps,Kubernetes\n",
            "EDUCATION______________________________________________________________________________________________________________________________________________________________________________MasterofScience-DataScience|UniversityoftheCumberlands,Williamsburg,Kentucky|GPA3.5MasterofScience-IndustrialandSystemsEngineering(MinorinDataScience)|LehighUniversity,PA|GPA:3.5BachelorofEngineering-MechanicalEngineering|BITSPilani,Dubai,UAE|GPA:3.5______________________________________________________________________________________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/snowflake_jd.txt', 'r') as f:\n",
        "  job_desc_context = f.read()\n",
        "\n",
        "job_desc_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "66Gl1gotnIwe",
        "outputId": "c88f7eff-a719-42d2-ca06-7a6c487ad97e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Senior, Data Scientist\\nWalmart · Hoboken, NJ Reposted 1 week ago · Over 100 applicants\\n$108,000/yr - $216,000/yr  Full-time  Mid-Senior level\\n10,001+ employees · Retail\\n60 connections work here · 3 company alumni work here · 22 school alumni work here\\n6 of 10 skills match your profile - you may be a good fit\\nView verifications related to this job post.View verifications related to this job post.\\nShow all\\n\\nApply\\n\\nSave\\nSave Senior, Data Scientist at Walmart\\nShare\\nShow more options\\nSenior, Data Scientist\\nWalmart Hoboken, NJ\\n\\nApply\\n\\nSave\\nSave Senior, Data Scientist at Walmart\\nShow more options\\nAbout the job\\nPosition Summary...\\n\\nWhat you'll do...\\n\\nSenior Data Scientist\\n\\nAt Walmart, we pride ourselves for knowing our customers and connecting with them better than any other company. We interact with our customers across more categories than any company in the world.\\n\\nThe Customer Decision Science team, which is a part of the Customer Insights & Strategy team within the Marketing org at Walmart, analyzes every store trip, web and app visit, service interaction, search, click, purchase, and survey response to help deliver the easiest shopping experience digitally and physically. We are a team comprised of decision science practitioners who work together to uncover the why behind the customer behavior while measuring the outcomes from a customer and competitive lens.\\n\\nAs a Senior Data Scientist in the team, you will have the unique opportunity to leverage the power of technology, big data and analytics to improve the lives of the 100M+ households that shop at Walmart every year.\\n\\nYou will be responsible for identifying accelerators and decelerators of customer loyalty and supporting strategic executive initiatives in related areas.\\n\\nOur ideal candidate is a sharp, thoughtful, and collaborative problem solver, who enjoys identifying key business levers and challenges, and then building data science and analytics frameworks to enable data-informed decision making. You will have direct visibility with executive leadership and will drive initiatives to support the rapid growth of our online and omni-channel customer base value. You will work closely with your peers and cross-functional partners to inform and craft executive narratives and provide business insights and analysis with a robust foundation.\\n\\nYou also have a strong combination of business acumen and data science background, as well as an intense hunger to make a significant business impact by owning and driving business outcomes.\\n\\nThis is a full-time position and will report to the Senior Director of Customer Decision Science.\\n\\nAbout Walmart Marketing\\n\\nNamed Ad Age's Marketer of the Year in 2022, you'll join an internationally recognized team of thinkers, creators, and problem solvers passionate about helping people save money and live better.\\n\\nWalmart Marketing is a dynamic, multidimensional organization dedicated to redefining how the world shops through impactful creative and fast-paced innovation - all grounded in customer insights and brand strategy. We live out our company values each day while striving to exceed customer expectations and drive growth for the company.\\n\\nWe orchestrate marketing campaigns and experiences that reach millions of daily shoppers. Our work spans the digital and physical spaces and combines the work of numerous internal teams and external advertising and media agencies. Our teams work together to show our customers how they can save money and live better. If you are motivated by complex challenges and want to build the future of commerce and consumer services, a Marketing role at Walmart could be what you've been looking for.\\n\\nOur Marketing team has flexibility on location. You can live within driving distance to one of our hubs in San Bruno, CA or Hoboken, NJ. We're moving toward 3 days in the office per week, with flexibility.\\n\\nYou Will Make An Impact By\\n\\nWell balanced skills - People have trouble pinning you down. Both business and technical/ data teams claim you as their own. You are equal parts technical and functional. You are equally comfortable and effective in persuading both technical and business audiences\\nData science & analytics expertise - You excel at designing and building new and impactful metrics to identify and quantify trends, patterns and data relationships. You are very comfortable rolling up your sleeves when needed and writing complex SQL queries and helping junior associates debug their work to raise the bar. You are adept at leveraging data science and algorithms frameworks in a practical business setting and have mastery over the fundamentals of supervised, unsupervised learning and/or causal inference. You can use your expert understanding of data structures in order scope and define data needs to execute projects.\\nProject ownership - You operate with a high agency mindset and can independently lead, execute and oversee end-to-end projects with a high degree of ambiguity. You set ambitious timelines for yourself/team and commit to them while adapting to changing priorities. You have strong organizational skills that enable you to manage multiple priorities, set expectations and collaborate across stakeholders, managers, and peers.\\nBusiness acumen - You can translate insights into relevant business recommendations, anticipate the needs of business stakeholders and connect the dots across various teams, research, and insights in order to build convincing and synthesized business recommendations.\\nGreat communicator - You're capable of telling the story behind the data to an executive audience and a pro at building slide decks that can simplify any complex story. You can customize your communication style based on stakeholders. You can guide and coach junior associates on story types, structures, and techniques based on context.\\nData visualization - You are a pro at leveraging visualization to build compelling stories based on context to integrate multiple pieces of information into cohesive insights.\\nPeople leadership - You have experience in mentoring and coaching junior data science talent and can influence without direct authority.\\n\\nYou'll Sweep Us Off Our Feet If You\\n\\nPartner with C-suite, corporate strategy, finance, marketing, merchandising, research, product, data science and analytics organizations to drive outcomes and influence strategic and tactical decision-making\\nDevelop and implement quantitative analyses, predictive models and customer KPIs to uncover insights on the customer journey and identify cause-effect relationships between business actions and customer outcomes\\nIdentify high value customer actions across Walmart products/services that will help Walmart meet customer needs better; evaluate behaviors and actions that unlock incremental value by leveraging causal analysis methodologies\\nTranslate and simplify data-informed insights into actionable business recommendations, implications and relevant data products\\nDevelop visualizations and presentations to clearly and effectively communicate insights and recommendations to stakeholders and leadership\\nPartner with data and technical engineers to define data and tracking requirements\\n\\nMinimum Qualifications\\n\\nBA/BS in Marketing, Mathematics, Computer Science, Statistics, Economics or related field with 4-6 years of experience in data science, data analytics and/or decision science; or Master's degree in relevant fields with 2-4 years of experience\\nAdvanced expertise in writing and debugging complex and efficient SQL code\\nExperience with at least one scripting language (R or Python) for data manipulation and visualization using packages like pandas/dplyr and ggplot/matplotlib/plotly\\nProven experience in leading data-driven projects from definition to execution, driving and influencing business decisions and outcomes\\nPractical experience in designing business metrics, time series analyses and forecasting techniques, cohort and survival analyses\\nFundamental knowledge of applied statistics and machine learning methods, such as regression, clustering, classification\\nDirect experience working with very large datasets\\nPresentation experience and a proven track record of using insights to influence stakeholders and colleagues\\n\\nPreferred Qualifications\\n\\nExperience leveraging cloud-based big data technologies (Hive/Hadoop) to explore, transform and blend data from multiple sources to answer multi-dimensional business questions\\nExperience researching new techniques and utilizing open-source learning frameworks (e.g. scikit-learn)\\nFamiliarity with causal inference and attribution methodologies\\nRetail/e-commerce domain experience\\n\\nExperience comes in many forms - skills are transferable, and passion goes a long way. We know that diversity makes for the best problem-solving and creative thinking, which is why we're dedicated to adding new perspectives to the team.\\n\\nHow You'll Thrive At Walmart\\n\\nPerformance-based incentive awards\\n401k with company match\\nDiscounted employee stock purchase plan\\nPaid parental leave,\\nNew surrogacy & adoption benefits\\nUnlimited Flex Time Off\\nWorking alongside a diverse group of collaborative and innovative team members\\nOpportunity for growth and development across several areas of the Fortune 1 organization\\nAnd much more\\n\\nEqual Opportunity Employer\\n\\nWalmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\\n\\nWho We Are\\n\\nJoin Walmart and your work could help over 275 million global customers live better every week. Yes, we are the Fortune #1 company. But you'll quickly find we're a company who wants you to feel comfortable bringing your whole self to work. A career at Walmart is where the world's most complex challenges meet a kinder way of life. Our mission spreads far beyond the walls of our stores. Join us and you'll discover why we are a world leader in diversity and inclusion, sustainability, and community involvement. From day one, you'll be empowered and equipped to do the best work of your life. careers.walmart.com\\n\\nAt Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.\\n\\nYou will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .\\n\\nLive Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.\\n\\nEligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .\\n\\nThe annual salary range for this position is $108,000.00-$216,000.00\\n\\nAdditional Compensation Includes Annual Or Quarterly Performance Incentives.\\n\\nAdditional compensation for certain positions may also include:\\n\\n Regional Pay Zone (RPZ) (based on location)\\n Stock equity incentives\\n\\nMinimum Qualifications...\\n\\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\\n\\nOption 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\\n\\nPreferred Qualifications...\\n\\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\\n\\nData science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\\n\\nPrimary Location...\\n\\n221 RIVER ST, HOBOKEN, NJ 07030, United States of America\\nPay found in job post\\nRetrieved from the description.\\n\\nIs this accurate?\\n\\nYes\\n/\\n\\nNo\\nBase salary\\n$108,000/yr - $216,000/yr (from job description)\\n\\nBenefits found in job post\\n401(k)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "o3rC-ZL2nLvU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def get_completion(prompt: str, model: str = \"gpt-4\") -> str:\n",
        "    \"\"\"\n",
        "    Query your LLM model with your prompt.\n",
        "    Parameters:\n",
        "    prompt (str): The text prompt you want the LLM to respond to.\n",
        "    model (str, optional): The model to be used for generating the response. Default is \"gpt-3.5-turbo\".\n",
        "    Returns:\n",
        "    str: The generated text completion from the specified model.\n",
        "    \"\"\"\n",
        "    openai.api_key = \"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\"\n",
        "    num_tokens = num_tokens_from_string(prompt, \"gpt-4\")\n",
        "    if num_tokens > 8192:\n",
        "      print(str(num_tokens)+\" :Too Long For GPT 4\")\n",
        "      return 0\n",
        "\n",
        "    else:\n",
        "      print(\"Number of tokens: \"+str(num_tokens))\n",
        "      input_cost = (int(num_tokens)/1000)*0.03\n",
        "      print(\"Cost Incurred Input: \"+str(input_cost))\n",
        "      messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "      start = time.time()\n",
        "      response = openai.ChatCompletion.create(\n",
        "          model= model,\n",
        "          messages=messages,\n",
        "          temperature=0.5\n",
        "      )\n",
        "      output_cost = (int(num_tokens_from_string(response.choices[0].message[\"content\"], \"gpt-4\"))/1000)*0.06\n",
        "      print(\"Cost Incurred Output: \"+str((int(num_tokens_from_string(response.choices[0].message[\"content\"], \"gpt-4\"))/1000)*0.06))\n",
        "      return [response.choices[0].message[\"content\"], input_cost+output_cost, time.time()-start]\n",
        "\n",
        "def resume_parser(task='skill_extraction', input_to_llm=''):\n",
        "\n",
        "  class resume_details(BaseModel):\n",
        "      sections_of_resume: list = Field(description=\"Different Sections of the Resume split by comma\")\n",
        "      professional_experience: list = Field(description=\"List of Companies Worked In describing Professional Acheivements during each job with success metrics and technologies used\")\n",
        "      education: list = Field(description=\"List of Educational Qualifications with University and Degree Obtained\")\n",
        "      skills: list = Field(description=\"List of Technical and Soft Skills\")\n",
        "\n",
        "  class resume(BaseModel):\n",
        "      resume: List[resume_details]\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  You are an AI assistant tasked at evaluating a professional job resume. Extract the following key elements from the resume :\n",
        "  Resume Text to be evaluated:\n",
        "  {input_to_llm}\n",
        "  \"\"\"\n",
        "  pydantic_object=resume\n",
        "  pydantic_parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
        "  format_instructions = pydantic_parser.get_format_instructions()\n",
        "  query = prompt\n",
        "  prompt = PromptTemplate(\n",
        "      template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "      input_variables=[\"query\"],\n",
        "      partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        "  )\n",
        "  _input = prompt.format_prompt(query=query)\n",
        "  answer = get_completion(_input.to_string())\n",
        "  return answer\n",
        "\n",
        "resume = resume_parser(input_to_llm=pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14_09hSAlqnB",
        "outputId": "325b0114-31fd-4861-dae4-01ff8f7659a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 2639\n",
            "Cost Incurred Input: 0.07916999999999999\n",
            "Cost Incurred Output: 0.057479999999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sections_of_resume = ast.literal_eval(resume[0])['resume'][0]['sections_of_resume']\n",
        "professional_experience = ast.literal_eval(resume[0])['resume'][0]['professional_experience']\n",
        "education = ast.literal_eval(resume[0])['resume'][0]['education']\n",
        "skills = ast.literal_eval(resume[0])['resume'][0]['skills']"
      ],
      "metadata": {
        "id": "7cJNUUBZ2weO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def get_completion(prompt: str, model: str = \"gpt-4\") -> str:\n",
        "    \"\"\"\n",
        "    Query your LLM model with your prompt.\n",
        "    Parameters:\n",
        "    prompt (str): The text prompt you want the LLM to respond to.\n",
        "    model (str, optional): The model to be used for generating the response. Default is \"gpt-3.5-turbo\".\n",
        "    Returns:\n",
        "    str: The generated text completion from the specified model.\n",
        "    \"\"\"\n",
        "    openai.api_key = \"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\"\n",
        "    num_tokens = num_tokens_from_string(prompt, \"gpt-4\")\n",
        "    if num_tokens > 8192:\n",
        "      print(str(num_tokens)+\" :Too Long For GPT 4\")\n",
        "      return 0\n",
        "\n",
        "    else:\n",
        "      print(\"Number of tokens: \"+str(num_tokens))\n",
        "      input_cost = (int(num_tokens)/1000)*0.03\n",
        "      print(\"Cost Incurred Input: \"+str(input_cost))\n",
        "      messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "      start = time.time()\n",
        "      response = openai.ChatCompletion.create(\n",
        "          model= model,\n",
        "          messages=messages,\n",
        "          temperature=0.5\n",
        "      )\n",
        "      output_cost = (int(num_tokens_from_string(response.choices[0].message[\"content\"], \"gpt-4\"))/1000)*0.06\n",
        "      print(\"Cost Incurred Output: \"+str((int(num_tokens_from_string(response.choices[0].message[\"content\"], \"gpt-4\"))/1000)*0.06))\n",
        "      return [response.choices[0].message[\"content\"], input_cost+output_cost, time.time()-start]\n",
        "\n",
        "def job_description_inferencer(task='skill_extraction', input_to_llm=''):\n",
        "\n",
        "  class job_details(BaseModel):\n",
        "      reponsibilities: list = Field(description=\"List of Resposibilities for the job\")\n",
        "      technical_requirements: list = Field(description=\"List of Technical Requirements for the job\")\n",
        "      educational_requirements: list = Field(description=\"List of Educational Requirements for the job\")\n",
        "      keywords: list = Field(description=\"List of Job Specific Keywords\")\n",
        "      team: list = Field(description=\"Description of the team\")\n",
        "      location: list = Field(description=\"Location of the Job\")\n",
        "      salary_range: list = Field(description=\"Salary Range of the Job\")\n",
        "      years_of_experience: list = Field(description=\"Years of Experience Needed for the Job\")\n",
        "      skills: list = Field(description=\"List of Technical and Soft Skills\")\n",
        "\n",
        "  class job(BaseModel):\n",
        "      job: List[job_details]\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  You are an AI assistant tasked at evaluating a job posting. Extract the following key elements from the job posting :\n",
        "  Job Posting to be evaluated:\n",
        "  {input_to_llm}\n",
        "  \"\"\"\n",
        "  pydantic_object=job\n",
        "  pydantic_parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
        "  format_instructions = pydantic_parser.get_format_instructions()\n",
        "  query = prompt\n",
        "  prompt = PromptTemplate(\n",
        "      template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "      input_variables=[\"query\"],\n",
        "      partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        "  )\n",
        "  _input = prompt.format_prompt(query=query)\n",
        "  answer = get_completion(_input.to_string())\n",
        "  return answer\n",
        "\n",
        "job_details = job_description_inferencer(input_to_llm=job_desc_context)\n",
        "job_details"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS-fibXopV8Y",
        "outputId": "d631fd6a-8d0e-486c-94c5-31d702359a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 3060\n",
            "Cost Incurred Input: 0.09179999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ast.literal_eval(job_details[0])['job'][0]['reponsibilities']"
      ],
      "metadata": {
        "id": "cPRHDGRj1j3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responsibilities = ast.literal_eval(job_details[0])['job'][0]['reponsibilities']\n",
        "educational_requirements = ast.literal_eval(job_details[0])['job'][0]['educational_requirements']\n",
        "technical_requirements = ast.literal_eval(job_details[0])['job'][0]['technical_requirements']\n",
        "keywords = ast.literal_eval(job_details[0])['job'][0]['keywords']\n",
        "team = ast.literal_eval(job_details[0])['job'][0]['team']\n",
        "location = ast.literal_eval(job_details[0])['job'][0]['location']\n",
        "salary_range = ast.literal_eval(job_details[0])['job'][0]['salary_range']\n",
        "years_of_experience = ast.literal_eval(job_details[0])['job'][0]['years_of_experience']\n",
        "skills = ast.literal_eval(job_details[0])['job'][0]['skills']"
      ],
      "metadata": {
        "id": "heDNtJzB0u7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(professional_experience)"
      ],
      "metadata": {
        "id": "9GbX8ENJ1xYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def get_completion(prompt: str, model: str = \"gpt-4\") -> str:\n",
        "    \"\"\"\n",
        "    Query your LLM model with your prompt.\n",
        "    Parameters:\n",
        "    prompt (str): The text prompt you want the LLM to respond to.\n",
        "    model (str, optional): The model to be used for generating the response. Default is \"gpt-3.5-turbo\".\n",
        "    Returns:\n",
        "    str: The generated text completion from the specified model.\n",
        "    \"\"\"\n",
        "    openai.api_key = \"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\"\n",
        "    num_tokens = num_tokens_from_string(prompt, \"gpt-4\")\n",
        "    if num_tokens > 8192:\n",
        "      print(str(num_tokens)+\" :Too Long For GPT 4\")\n",
        "      return 0\n",
        "\n",
        "    else:\n",
        "      print(\"Number of tokens: \"+str(num_tokens))\n",
        "      input_cost = (int(num_tokens)/1000)*0.03\n",
        "      print(\"Cost Incurred Input: \"+str(input_cost))\n",
        "      messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "      start = time.time()\n",
        "      response = openai.ChatCompletion.create(\n",
        "          model= model,\n",
        "          messages=messages,\n",
        "          temperature=0.5\n",
        "      )\n",
        "      output_cost = (int(num_tokens_from_string(response.choices[0].message[\"content\"], \"gpt-4\"))/1000)*0.06\n",
        "      print(\"Cost Incurred Output: \"+str((int(num_tokens_from_string(response.choices[0].message[\"content\"], \"gpt-4\"))/1000)*0.06))\n",
        "      return [response.choices[0].message[\"content\"], input_cost+output_cost, time.time()-start]\n",
        "\n",
        "def ecperience_modifier(task='skill_extraction', input_to_llm='', responsibilities='', keywords='', technical_requirements='', skills=''):\n",
        "\n",
        "  class experience_modifier(BaseModel):\n",
        "      modified_job_experiences: list = Field(description=\"Generate modified job experiences to account for responbilities and requirements mentioned in the context keeping inclusion of keywords in mind\")\n",
        "\n",
        "  class experience(BaseModel):\n",
        "      experience: List[experience_modifier]\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  You are an AI assistant tasked at modifying job experiences to suit a job posting based on requirements, responsibilities and keywords:\n",
        "\n",
        "  Responsibilities: {responsibilities}\n",
        "  Keywords: {keywords}\n",
        "  Technical Requirements: {technical_requirements}\n",
        "  Skills: {skills}\n",
        "\n",
        "  Job Experiences to be evaluated:\n",
        "  {input_to_llm}\n",
        "\n",
        "  Perform the following steps:\n",
        "  (1) Extract each job experience\n",
        "  (2) Ensure responsibilities and technical requirements required are included in the form of relevant made up acheivements in all of the experiences\n",
        "  (3) Insert the above keywords wherever applicable as a skill or an experience\n",
        "  (4) Ensure the skills required above are included in the form of relevant made up acheivements in all of the experiences\n",
        "  (5) Return the modified job experiences and check they are gramatically correct and make sense\n",
        "\n",
        "  Make the new additions as diverse and distinct as possible. Return the output in a professional resume friendly format\n",
        "  \"\"\"\n",
        "  pydantic_object=experience\n",
        "  pydantic_parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
        "  format_instructions = pydantic_parser.get_format_instructions()\n",
        "  query = prompt\n",
        "  prompt = PromptTemplate(\n",
        "      template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "      input_variables=[\"query\"],\n",
        "      partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        "  )\n",
        "  _input = prompt.format_prompt(query=query)\n",
        "  answer = get_completion(_input.to_string())\n",
        "  return answer\n",
        "\n",
        "modified_experience = ecperience_modifier(input_to_llm=str(professional_experience), responsibilities=responsibilities, keywords=keywords, technical_requirements=technical_requirements, skills=skills)\n",
        "modified_experience"
      ],
      "metadata": {
        "id": "7N3MrlgF4T9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ast.literal_eval(modified_experience[0])"
      ],
      "metadata": {
        "id": "swqEV5rW4rwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tybtgz1S75BU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}